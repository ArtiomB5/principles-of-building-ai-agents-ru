# 17
## ОСНОВЫ RAG

RAG позволяет агентам поглощать пользовательские данные и синтезировать их со своей глобальной базой знаний, чтобы давать пользователям качественные ответы.
Вот как это работает.

*   **Разбиение на фрагменты (Chunking):** Вы начинаете с того, что берете документ (хотя мы можем использовать и другие типы источников) и разбиваете его на фрагменты. Мы хотим разделить документ на удобные для поиска части.
*   **Создание векторов (Embedding):** После разбиения вы захотите создать эмбеддинги ваших данных – преобразовать их в вектор, или массив из 1536 значений между 0 и 1, представляющих смысл текста.
    Мы делаем это с помощью LLM, потому что они делают эмбеддинги гораздо точнее; у OpenAI есть API для этого, есть другие поставщики, такие как Voyage или Cohere.
    Вам нужна векторная БД, которая может хранить эти векторы и выполнять математические операции для поиска по ним.
    Вы можете использовать pgvector, который поставляется в комплекте с Postgres.
*   **Индексация (Indexing):** После выбора векторной БД вам необходимо настроить индекс для хранения фрагментов ваших документов, представленных в виде векторных эмбеддингов.
*   **Запрос (Querying):** Хорошо, после этой настройки вы теперь можете выполнять запросы к базе данных!
    *Под капотом* вы будете запускать алгоритм, который сравнивает вашу строку запроса со всеми фрагментами в базе данных и возвращает наиболее похожие.
    Самый популярный алгоритм называется «косинусное сходство (cosine similarity)».
    Реализация похожа на геопространственный запрос, ищущий широту/долготу, за исключением того, что поиск ведется по 1536 измерениям вместо двух.
    Вы можете использовать и другие алгоритмы.
*   **Переранжирование (Reranking):** Опционально, после запроса вы можете использовать переранжировщик. Переранжирование – это более требовательный к вычислениям способ поиска по набору данных. Вы можете запустить его для ваших результатов, чтобы улучшить порядок (но запуск его для всей базы данных занял бы слишком много времени).
*   **Синтез (Synthesis):** наконец, вы передаете ваши результаты как контекст в LLM, вместе с любым другим контекстом, и она может синтезировать ответ для пользователя.