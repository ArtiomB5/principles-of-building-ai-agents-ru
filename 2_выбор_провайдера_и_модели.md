# 2  
## ВЫБОР ПРОВАЙДЕРА И МОДЕЛИ

Один из первых выборов, который вам предстоит сделать при создании ИИ-приложения, — это решить, на какой модели строить. Вот некоторые соображения:

### **Хостинг vs открытый исходный код**

Первый совет, который мы обычно даем людям при создании ИИ-приложений, — начать с хостингового провайдера, такого как OpenAI, Anthropic или Google Gemini.  
Даже если вы думаете, что вам потребуется использовать модели с открытым исходным кодом, прототипируйте с помощью облачных API, иначе вы будете отлаживать проблемы с инфраструктурой вместо того, чтобы итеративно улучшать свой код. Один из способов сделать это без переписывания большого количества кода — использовать библиотеку маршрутизации моделей (об этом позже).

### **Размер модели: точность vs стоимость/задержка**

Большие языковые модели работают путем перемножения массивов и матриц чисел. У каждого провайдера есть более крупные модели, которые дороже, точнее и медленнее, и меньшие модели, которые быстрее, дешевле и менее точны.  
Мы обычно рекомендуем начинать с более дорогих моделей при прототипировании — как только вы получите работающий вариант, вы можете оптимизировать стоимость.

### **Размер контекстного окна**

Одной из переменных, о которой вам, возможно, стоит подумать, является «контекстное окно» вашей модели. Сколько токенов оно может принять? Иногда, особенно для раннего прототипирования, вы можете захотеть передать модели огромные объемы контекста, чтобы сэкономить усилия по выбору релевантного контекста.  
На данный момент самые длинные контекстные окна принадлежат набору моделей Google Gemini Flash; Gemini Flash 1.5 Pro поддерживает контекстное окно в 2 миллиона токенов (примерно 4000 страниц текста).  
Это позволяет реализовать некоторые интересные приложения; вы можете представить себе помощника поддержки, имеющего всю кодовую базу в своем контекстном окне.

### **Модели с рассуждением**

Другой тип моделей — это так называемые «модели с рассуждением», а именно те, которые выполняют много внутренней логики, прежде чем вернуть ответ. Ответ может занимать секунды или минуты, и он будет возвращен целиком (при этом в процессе может передаваться некоторый «процесс размышления»).  
Модели с рассуждением становятся намного лучше, и делают это быстро. Теперь они способны разбирать сложные проблемы и фактически «обдумывать» их шаг за шагом, почти как человек.  

Что изменилось? Новые методы, такие как промптинг «chain-of-thought», позволяют этим моделям показывать свою работу шаг за шагом. Что еще лучше, более новые методы, такие как «chain of draft» и «chain of preference optimization», помогают им оставаться сосредоточенными. Вместо того чтобы пространно расписывать каждую мельчайшую деталь или повторяться, они переходят к сути, делясь только самыми важными шагами и пропуская лишнее. Это означает, что вы получаете ясные, эффективные рассуждения, а не сплошную стену текста.  

Суть в следующем: если вы дадите этим моделям достаточно контекста и хороших примеров, они могут давать удивительно умные, качественные ответы на сложные вопросы. Например, если вы хотите, чтобы модель помогла диагностировать сложный медицинский случай, предоставление ей истории болезни пациента, симптомов и нескольких примеров случаев приведет к гораздо лучшим результатам, чем просто задавание расплывчатого вопроса. Трюк остается тем же: чем больше вы поможете им на начальном этапе, тем лучше становятся их рассуждения.  

Вам следует думать о моделях с рассуждением как о «генераторах отчетов» — вам нужно предоставить им много контекста заранее с помощью «многопримерного» промптинга (об этом позже). Если вы это сделаете, они смогут возвращать высококачественные ответы. Если нет, они сойдут с рельсов.

### **Провайдеры и модели (май 2025 г.)**

| Provider       | Form factor(s) | Default model     | Cheap/fast model        | Reasoning model(s)                  |
|----------------|----------------|-------------------|-------------------------|-------------------------------------|
| OpenAI         | Hosted         | GPT-4.1, 4o       | GPT-4.1 mini, 4o-mini   | o4-mini, o4-mini-high, o3, o1-pro, o3-mini |
| Anthropic      | Hosted         | sonnet            | haiku                   | None                               |
| Google Gemini  | Hosted         | gemini-1.5-pro    | gemini-1.5-flash        | None                               |
| Mistral        | OSS            | mistral-next      | mistral-small           | None                               |
| Meta           | OSS            | llama3-8b         | llama3-2b               | None                               |
| DeepSeek       | OSS            | deepseek-V2       | None                    | deepseek-r1                        |
| Qwen (Alibaba) | OSS            | Qwen2-72B         | Qwen2-7B, Qwen1.8B      | None                               |